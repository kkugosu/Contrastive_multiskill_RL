# RL_META

## Installation
```
git clone https://github.com/kkugosu/RL_BASIC.git
```
## Experiment
```
python executable.py
```
you can choose belows
* environments 
* policy 
* batch size
* memory reset time
* train time per memory
* learning rate
* eligibility trace
* done penalty
* load previous model or not (not = 0 yes = 1)

## Algorithm


> [diayn](https://github.com/kkugosu/RL_META/blob/master/Docs/diayn.md)
>
> [vic](https://github.com/kkugosu/RL_META/blob/master/Docs/vic.md)
>
> [valor](https://github.com/kkugosu/RL_META/blob/master/Docs/valor.md)
>
> [visr](https://github.com/kkugosu/RL_META/blob/master/Docs/visr.md)
>
> [smm](https://github.com/kkugosu/RL_META/blob/master/Docs/smm.md)
>
> [edl](https://github.com/kkugosu/RL_META/blob/master/Docs/edl.md)
>
> [dads](https://github.com/kkugosu/RL_META/blob/master/Docs/dads.md)
>
> [aps](https://github.com/kkugosu/RL_META/blob/master/Docs/aps.md)
>
> [cic](https://github.com/kkugosu/RL_META/blob/master/Docs/cic.md)

## Experiment environment

* cartpole
* hopper


## Requirements

* Gym
* Mujoco
* Python >= 3.8 
* Pytorch >= 1.12.0
* Numpy


## REPO

https://arxiv.org/pdf/1802.06070.pdf
